<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"> 
<!--
Design by TEMPLATED
http://templated.co
Released for free under the Creative Commons Attribution License

Name       : Skeleton 
Description: A two-column, fixed-width design with dark color scheme.
Version    : 1.0
Released   : 20130902

--> 
<html xmlns="http://www.w3.org/1999/xhtml"> 
    <head> 
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/> 
        <title>Darren Cosker's Home Page</title>         
        <meta name="keywords" content=""/> 
        <meta name="description" content=""/> 
        <link href="../css/theme.css" rel="stylesheet" type="text/css"> 
        <link href="http://fonts.googleapis.com/css?family=Source+Sans+Pro:200,300,400,600,700,900" rel="stylesheet"/> 
        <link href="default.css" rel="stylesheet" type="text/css" media="all"/> 
        <link href="fonts.css" rel="stylesheet" type="text/css" media="all"/> 
        <!--[if IE 6]><link href="default_ie6.css" rel="stylesheet" type="text/css" /><![endif]-->         
    </head>     
    <body> 
        <div id="page" class="container"> 
            <div id="header"> 
                <div id="logo"> 
                    <img src="images/darren_6.jpg" alt="" width="165" height="165"/> 
                    <h2><a href="#">Prof. Darren Cosker</a></h2> 
                    <p><font color="white"><b>Principal Scientist Manager</b> @ Microsoft</font></p> 
                    <p><font color="white"><b>Professor</b> @ University of Bath/Royal Society Industry Fellow</font></p> <span></span> 
                    <p><font color="white">Royal Society Industry Fellow</font></p> <span></span> 
                    <p><font color="white">Contact: <a href="https://www.linkedin.com/in/darren-cosker-61271413/" LinkedIn< a> or <a href="https://twitter.com/dopomoc">X/Twitter</a></font></p> 
                </div>                 
                <div id="menu"> 
                    <ul> 
                        <li> <a href="http://www.camera.ac.uk">CAMERA</a> 
                        </li>                         
                        <li> <a href="#areas">RESEARCH AREAS</a> 
                        </li>                         
                        <li> <a href="#funding">FUNDING</a> 
                        </li>                         
                        <li> <a href="#team">TEAM</a> 
                        </li>                         
                        <li> <a href="#papers">PAPERS</a> 
                        </li>                         
                        <li> <a href="#commercial">COMMERCIAL</a> 
                        </li>                         
                        <li> <a href="#datasets">CODE+DATA</a> 
                        </li>                         
                        <li> <a href="#archive">ARCHIVE</a> 
                        </li>                         
                    </ul>                     
                </div>                 
            </div>             
            <div id="main" align="center"> 
                <div id="banner"> 
                    <img src="images/banner_v2.jpg" alt="" class="image-full"/> 
                </div>                 
                <!--
		<table width="200" border="0" align="center" cellpadding="10">
  <tbody>
    <tr>
      <td><img src="images/darren_6.jpg" alt="" width="150" height="150" /></td>
      <td>Prof. Darren Cosker
          <p>D.P.Cosker@bath.ac.uk</p>
          <p>Professor/Royal Society Industry Fellow</p></td>
    </tr>
  </tbody>
</table>
-->                 <a href="http://www.camera.ac.uk"><img src="images/CAMERA_C_logo.jpg" width="55" height="50" width="50" height="50" alt=""/></a> <a href="https://github.com/dopomoc"><img src="images/github_2.png" width="50" height="50"></a> <a href="https://twitter.com/dopomoc"><img src="images/twitter.png" width="50" height="50" alt=""/></a> <a href="https://www.linkedin.com/in/darren-cosker-61271413?trk=hp-identity-name"><img src="images/linkedin.png" width="50" height="50" alt=""/></a> 
                <div id="welcome" style="text-align: left"> 
                    <div class="title"> 
                        <!--<h2>Home</h2>-->                         
                    </div>                     
                    <p>I am a Principal Scientist Manager at Microsoft (since 2021) - based out of the Cambridge, UK office - where I work on AI for human understanding for Presence and Mixed Reality - in products such as Teams and Microsoft Mesh.</p> 
                    <p>Up to 2021 I was a full time Professor Computer Science at the University of Bath, where I joined as a Royal Academy of Engineering/ EPSRC Research Fellow in 2007 and still hold a small part-time position. I have been fortunate enough to be awarded two previous Research Fellowships: Royal Academy of Engineering, 2007-2012, Royal Society Industry Fellowship (with Double Negative Visual Effects), 2012-2016.</p> 
                    <p> In 2015 I founded and was Director of the <a>Centre for the Analysis of Motion, Entertainment Research and Applications (CAMERA)</a>, funded by EPSRC/AHRC, with partner contributions from The Imaginarium, The Foundry, British Skeleton, Ministry of Defence and British Maritime Technologies. In 2020 I led the successful re-funding of CAMERA for another 5 years (EPSRC) and helped secure the £45m+ MyWorld project in the South West of the UK. <p/> <p>My primary research interest has always been on human motion analysis, recognition and synthesis - particulary for animation with applications in Video Games, Virtual Worlds, Mixed Reality and Movies.</p> <!--<p><font color="#FF0004"><b>PhD/Post-Doctoral Researcher Opportunities!</b></font>I am currently looking for a post-doctoral researcher with a background in 3D computer vision, ideally with application areas/interests in real time tracking. There are also PhD opportunities within CAMERA in several areas across motion capture and animation. Experience/interest in Computer Vision, Graphics and/or machine learning is desirable. Please email me for enquiries.</p>-->  
                </div>                 
                <div class="title"> 
                    <h2>Ship it! Production and Commercial Projects</h2> <a name="commercial"></a> 
                </div>                 
                <div id="commercial"> 
                    <p>I have always been a believer that you shouldn't do research and then just 'throw it over the wall' for others to take to real users and customers. In fact, most of the hard - and really interesting work - starts when you get your great reseach ideas into real people hands. Then you find out a few things - does it really work on real data? Is it robust? You will discover dozens of things that are wrong,  could be improved, and even better a set of new problems. At Microsoft I have been fortunate to get research into the hands of millions of customers through Mesh and Teams. In <a href="http://www.camera.ac.uk">CAMERA</a> I created a model whereby we translated research into impact by creating tools from our research, deploying them into our studio, and then delivering projects to clients that leverage these tools. Below is a snapshot of some of the projects I have been fortunate enough to be involved in!</p> 
                    <table width="484" border="0" align="center"> 
                        <tbody> 
                            <tr> 
                                <td> 
                                    <img src="images/Mesh_Time.jpg" alt="" width="244" height="262"/> 
                                </td>
                                <td> 
                                    <img src="images/Mesh_Avatars.jpg" alt="" width="244" height="252"/> 
                                </td>                                 
                                <td> 
                                    <img src="images/Mesh_Immersive.jpg" alt="" width="220" height="200"/> 
                                </td>                                 
                            </tr>                             
                            <tr> 
                                <td><b>Microsoft Mesh</b> - Mesh is a platform that allows people to connect in virtual worlds - on desktop, or VR.</td> 
                                <td><b>Mesh Avatars in Teams</b> - Mesh Avatars are animated by voice using AI technology developed by myself and my team at Microsoft. </td>
                                <td><b>Immersive Meetings</b> - The Avatar technology and AI audio features are also shipped in 3D experiences on Quest and Windows. </td>
                            </tr>                             
                            <tr> 
                                <td> 
                                    <img src="images/Aardman.jpg" alt="" width="260" height="120"/> 
                                </td>                                 
                                <td> 
                                    <img src="images/BBC.jpg" alt="" width="240" height="110"/> 
                                </td>                                 
                                <td> 
                                    <img src="images/Cosmos.jpg" alt="" width="240" height="130"/> 
                                </td>                                 
                            </tr>                             
                            <tr> 
                                <td><b>11:11 Memories Retold</b> - with Aardman and Bandai Namco (BAFTA nominated). We delivered all motion capture for the video game at our CAMERA studio.</td> 
                                <td><b>'Is Anna OK?'</b> - with BBC and Aardman. An immersive experience delivered with our in-house facial rigging, animation and motion capture solution.</td> 
                                <td><b>Cosmos Within Us</b> - with Satore Studios (Cannes Lion Winner). We build digital doubles for performers and animated them using our in house tools.</td> 
                            </tr>                             
                        </tbody>                         
                    </table>                     
                </div>                 <br> 
                <div class="title"> 
                    <h2>Research Themes</h2> <a name="areas"></a> 
                </div>                 
                <p>I have always been interested in people - and understanding how they move so we can model this and then learn to create better animation systems. This involves peoples faces, bodies, the environment, each other - and then the application to video games, movies, remote communication. I believe motion should always be higher fidelity than appearance - and poor appearance and great motion will always be better than great appearance and poor motion.</p> 
                <p>Along this direction I have explored many projects in the past - both in academia and industry - and established new teams as well as multiple commercial grade motion capture production studios. Below is an overview of my research based on different areas I have worked on. It is a representative list of papers only by broad topic area - for a full list see the <a href="#papers">research papers</a> section.</p> 
                <table width="484" border="0" align="center"> 
                    <tbody> 
                        <h3>Facial Analysis and Synthesis</h3> 
                        <tr> 
                            <td width="88"> 
                                <img src="images/CGF_2019.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/rigidity.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td width="89"> 
                                <img src="images/MIG_2016.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td width="89"> 
                                <img src="images/GI_2016.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td width="90"> 
                                <img src="images/iccv.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td width="90"> 
                                <img src="images/Vedran_IEEE.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/Trellis.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                        </tr>                         
                        <tr> 
                            <td>Evolutionary Facial Animation - CGF 2019</td> 
                            <td>Content Aware Deformation - CVMP 2015</td> 
                            <td>Procedural Facial Animation - CGF 2018</td> 
                            <td>Reading Between the Dots: Facial Capture- GI 2017</td> 
                            <td>Dynamic Morphable Models: D3DFACS - ICCV 2011</td> 
                            <td>4D Facial Movement for Biometrics - IEEE SMC 2010</td> 
                            <td>Speech Driven Facial Animation - ICPR 2004</td> 
                        </tr>                         
                    </tbody>                     
                </table>                 
                <table width="484" border="0" align="center"> 
                    <tbody> 
                        <h3>Performance Capture and Animation</h3> 
                        <tr> 
                            <td> 
                                <img src="images/RGBDDog.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/CGI_2019.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/SPORT_2018.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/FOOT_2018.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/MIG_2018.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                        </tr>                         
                        <tr> 
                            <td>RGBD-Dog: Predicting Canine Pose from RGBD  - CVPR 2020</td> 
                            <td>Scale Aware Performance Retargeting - CGI 2019</td> 
                            <td>Markerless Motion Capture Survey - Sports Medicine 2018</td> 
                            <td>Markerless Sprint Analysis - WACV 2018</td> 
                            <td>Elastic Deformation - MIG 2018</td> 
                        </tr>                         
                    </tbody>                     
                </table>                 
                <table width="484" border="0" align="center"> 
                    <tbody> 
                        <h3>Image and Video Processing</h3> 
                        <tr> 
                            <td> 
                                <img src="images/NIPS_2018.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/CVPR_2018.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/blur_robust.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/inferring.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/bmvc14.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/anchor_patch.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                        </tr>                         
                        <tr> 
                            <td>Image to Image Translation - NeurIPS 2018</td> 
                            <td>Multi-task Learning - CVPR 2018</td> 
                            <td>Blur Robust Robust Optical Flow - PR 2017</td> 
                            <td>Inferring Focal Length - CG 2015</td> 
                            <td>Shadow Removal - BMVC 2014</td> 
                            <td>Robust Feature Tracking - ACCV 2013</td> 
                        </tr>                         
                        <tr> 
                            <td></td> 
                            <td> 
                                <img src="images/digipro.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/LME_Faces.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/RAL_2016.bmp" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/TVCG_Water.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                        </tr>                         
                        <tr> 
                            <td></td> 
                            <td>Camera Tracking in Visual Effects - DigiPro 2016</td> 
                            <td>Mesh based Optical Flow - CVPR 2013</td> 
                            <td>Non-Rigid Optical Flow Ground Truth - RAL 2016</td> 
                            <td>Water Reconstruction from Video - TVCG 2015</td> 
                        </tr>                         
                    </tbody>                     
                </table>                 
                <table width="484" border="0" align="center"> 
                    <tbody> 
                        <h3>Applied Perception for Vision and Graphics</h3> 
                        <tr> 
                            <td> 
                                <img src="images/APGV_2010.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/smile_traj_.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/McGurk.png" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/sap_2016.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                            <td> 
                                <img src="images/hci.jpg" alt="" width="100" height="80"/> 
                            </td>                             
                        </tr>                         
                        <tr> 
                            <td>Nonlinear 4D Facial Perception - ACM APGV / SAP 2011</td> 
                            <td>Facial Dynamics and Trustworthiness - Emotion 2008 </td> 
                            <td>Perceptual Evaluation of Video Based Facial Animation - ACM TAP 2005</td> 
                            <td>Evaluation of Foveated Rendering Methods - ACM SAP 2016</td> 
                            <td>Evaluation of Gesture Based Interfaces - Pervasive 2011</td> 
                        </tr>                         
                    </tbody>                     
                </table>                 
                <table width="484" border="0" align="center"> 
                    <tbody> 
                        <h3>Virtual and Augmented Reality</h3> 
                        <tr> 
                            <td> 
                                <img src="images/IEEEVR.jpg" alt="" width="75" height="75"/> 
                            </td>                             
                            <td> 
                                <img src="images/ISMAR_2019.jpg" alt="" width="75" height="75"/> 
                            </td>                             
                            <td> 
                                <img src="images/SIGGRAPH_2019.jpg" alt="" width="75" height="75"/> 
                            </td>                             
                            <td> 
                                <img src="images/SCA_2019.jpg" alt="" width="75" height="75"/> 
                            </td>                             
                            <td> 
                                <img src="images/vrst.jpg" alt="" width="75" height="75"/> 
                            </td>                             
                            <td> 
                                <img src="images/u4.jpeg" alt="" width="100" height="80"/> 
                            </td>                             
                        </tr>                         
                        <tr> 
                            <td>Real World Objects for Egocentric VR - IEEEVR 2020</td> 
                            <td>Creating Virtual Props - ISMAR 2019</td> 
                            <td>Real Time Object Deformation for VR - SIGGRAPH 2019 (poster)</td> 
                            <td>Multi-Camera / RGBD Object Tracking - SCA 2019</td> 
                            <td>Tracking Head Mounted Displays - VRST 2014</td> 
                            <td>Latency Aware Foveated Rendering - CVMP 2015</td> 
                        </tr>                         
                    </tbody>                     
                </table>                 <br> <br> 
                <div class="title"> 
                    <h2>Alumni</h2> <a name="team"></a> 
                </div>                 
                <div id="team"> 
                    <p>At Microsoft I lead a team of amazingly talented scientists and engineers. But as a Professor and previous Director of CAMERA I was also fortunate to work with some amazing students, researchers and engineers.</p> 
                    <p> Martin Parsons (CAMERA),  Murray Evans (CAMERA), Yiguo Qiao (Living With/RUH/InnovateUK), Jack Saunders, George Fletcher, Jake Deane, Kyle Reed (Cubic Motion); Jose Serra (Digital Domain/ ILM), Anamaria Ciucanu (MMU), Pedro Mendes, Shridhar Ravikumar (Amazon, Apple); Alastair Barber (The Foundry); Wenbin Li (Bath); Han Gong (Apple); Charalampos Koniaris (Disney Research); Daniel Beale; Sinan Mutlu (Framestore); Nicholas Swafford; Nadejda Roubtsova (CAMERA); Sinead Kearney (CAMERA); Maryam Naghizadeh; Catherine Taylor (Marshmallow Laser Feast)</p> 
                    <bl> </bl>                     
                    <ul class="actions"> 
                        <li> <a href="#" class="button">Etiam posuere</a> 
                        </li>                         
                    </ul>                     
                </div>                 
                <div class="title"> 
                    <h2>Research Funding and Awards</h2> <a name="funding"></a> 
                </div>                 
                <div id="grants"> 
                    <p>(PI) 2020-2025: CAMERA 2.0 - Centre for the Analysis of Motion, Entertainment Research and Applications (£4,151,614 FEC). <strong>EPSRC</strong></p> 
                    <p>(PI) 2019-2021: CAMERA Motion Capture Innovation Studio (£901,391) <strong>Horizon 2020</strong></p> 
                    <p>(PI) 2019-2022: A tool to reveal Individual Differences in Facial Perception (£402,113) <strong>Medical Research Council (MRC) </strong></p> 
                    <p>(PI) 2018-2020: Rheumatoid Arthritis Flare Profiler (£165,126, Total project value £663,290). Partners: Living With, NHS. <strong>InnovateUK</strong></p> 
                    <p>(Co-I) 2018-2022: Bristol and Bath Creative Cluster (~£4m). Partners: UWE, University of Bristol, Bath Spa University. <strong>AHRC</strong></p> 
                    <p>(PI) 2017-2019: DOVE: Deformable Objects for Virtual Environments (£128,746, Total project value £562,559 FEC). Partner: Marshmallow Laser Feast, Heston's Fat Duck. <strong>Innovate UK</strong></p> 
                    <p>(PI) 2016-2018: HARPC: HMC for Augmented Reality Performance Capture (£119,025, Total project value £517,616 FEC). Partner: The Imaginarium. <strong>Innovate UK</strong></p> 
                    <p><p>(PI) 2015-2020: Centre for the Analysis of Motion, Entertainment Research and Applications - CAMERA (£ 4,998,728 FEC). Partners: The Imaginarium, The Foundry, Ministry of Defence, British Maratime Technologies, British Skeleton. <strong>EPSRC/AHRC</strong>. (not including partner contributions, ~£5,000,000).</p> <p>(PI) 2015-2017: Biped to Animal (£108,109 FEC). Parter: The Imaginarium.<strong> Innovate UK.</strong></p> <p>(PI) 2015: Goal Oriented Real Time Intelligent Performance Retargeting &nbsp;(£29,997 FEC). Partner: The Imaginarium. <strong>Innovate UK</strong>. </p> <p>(Co-I) 2013-2016: Acquiring Complete and Editable Outdoor Models from Video and Images (£1,003,256 FEC).<strong> EPSRC</strong>.</p> <p>(PI-Bath) 2014-2017: Visual Image Interpretation in Man and Machine (VIIMM) (£121,030 FEC). Partner: University of Birmingham. <strong>EPSRC</strong></p> <p>(PI) 2012-2016: Next Generation Facial Capture and Animation (£100,887 FEC). Partner: Double Negative Visual Effects. The <strong>Royal Society Industry Fellowship</strong>. </p> <p>(PI) 2007-2012: Exploiting 4D Data for Creating Next Generation Facial Modelling and Animation Techniques (£460,640FEC). <strong>The Royal Academy of Engineering Research Fellowship</strong>. </p> <p>Other funding: PhD Studentships, EPSRC Innovation Acceleration Account (IAA), Nuffield Foundation. </p> <bl> </bl>  
                </div>                 
                <div class="title"> 
                    <h2>Code and Data</h2> <a name="datasets"></a> 
                </div>                 
                <div id="data" style="text-align: left"> 
                    <p><strong>RGBD-Dog</strong> RGBD-Dog contains motion capture and multiview (Sony) RGB and (Kinect) RGBD data for several dogs performing different actions (all cameras and mo-cap syncronised with calibration data included. You can get the data, code to view and the CVPR 2020 paper it is all based on from our <a href="https://github.com/CAMERA-Bath/RGBD-Dog">GitHub page</a>. In our CVPR 2020 paper we use the data to train a model to predict dog pose from RGBD data. However, it also works pretty well on other animals. In the future we will expand the data and code as we publish more of our research. </p> 
                    <p><b>D3DFACS</b> The D3DFACS Dataset contains over 500 FACS coded dynamic 3D (4D) sequences from 10 individuals - including 3D meshes, stereo UV maps, colour camera images and calibration files. You can find out more about it in our ICCV 2011 paper "<a href="ICCV_final_2011.pdf">A FACS Valid 3D Dynamic Action Unit Database with Applications to 3D Dynamic Morphable Facial Modelling</a>". If you would like to download the dataset for academic research, <a href="https://vision.cs.bath.ac.uk/facedata">please visit the data set website</a></p> 
                    <p><b>Shadow
			Removal Ground Truth and Evaluation</b> To encourage the open comparison of single image
                  shadow removal in community, we provide an online
                  benchmark site and a dataset. Our quantitatively
                  verified high quality dataset contains a wide range of
                  ground truth data (214 test cases in total). Each case
                  is rated according to 4 attributes, which are texture,
                  brokenness, colourfulness and softness, in 3
                  perceptual degrees from weak to strong. To access the
                  evaluation website, <a href="http://www.cs.bath.ac.uk/%7Ehg299/shadow_eval/">please visit here</a>.</p> 
                    <p></p> <br> <br> 
                </div>                 <br> 
                <div id="papers"> 
                    <div class="title"> 
                        <h2>Publications</h2> <a name="papers"></a> 
                    </div>                     
                    <p>For a complete list of papers - see my <a href="https://scholar.google.co.uk/citations?user=n0rYM4kAAAAJ&hl=en">Google Scholar page</a>.</p> 
                    <ul class="style1"> 
                        <div id="copyright"> <span>&copy; Darren Cosker. All rights reserved. </span> <span>Design by <a href="http://templated.co" rel="nofollow">TEMPLATED</a>.</span> 
                        </div>                         
                </div>                 
            </div>
